# 本地开发环境搭建指南

## 1. 环境依赖

### 1.1 系统要求
- Windows 10/11 (64位)
- Python 3.12+
- 至少8GB RAM (推荐16GB以上)
- 至少10GB可用磁盘空间

### 1.2 核心依赖

| 依赖名称 | 版本要求 | 用途 |
|---------|---------|------|
| Python | 3.12+ | 核心编程语言 |
| LangChain | 最新稳定版 | LLM集成框架 |
| Ollama | 0.11.0+ | 本地LLM服务 |
| Click | 8.1+ | 命令行界面 |
| PyYAML | 6.0+ | 配置管理 |
| SQLite | 3.40+ | 数据持久化 |
| NLTK | 3.8+ | 文本分析 |
| scikit-learn | 1.3+ | 相似度计算 |
| asyncio | 内置 | 异步处理 |

## 2. 安装步骤

### 2.1 Python环境配置

1. **下载并安装Python**
   - 访问 [Python官网](https://www.python.org/downloads/) 下载Python 3.12+ 安装包
   - 运行安装包，勾选 "Add Python to PATH"
   - 选择 "Customize installation"，确保所有选项都被勾选
   - 完成安装后，打开命令行验证：
     ```powershell
     python --version
     pip --version
     ```

2. **安装现代化依赖管理工具**
   ```powershell
   pip install --upgrade pip
   pip install uv
   ```
   
   **uv** 是一个高性能的Python包管理器，具有以下优势：
   - 比pip快10-100倍
   - 自动管理虚拟环境
   - 内置依赖解析器
   - 支持pep 621标准
   - 自动同步依赖

### 2.2 Ollama安装与配置

1. **下载并安装Ollama**
   - 访问 [Ollama官网](https://ollama.com/) 下载Windows版本
   - 运行安装包完成安装

2. **启动Ollama服务**
   - 安装完成后，Ollama服务会自动启动
   - 打开命令行验证服务状态：
     ```powershell
     ollama --version
     ```

3. **下载所需模型**
   - 运行以下命令下载项目使用的默认模型：
     ```powershell
     ollama pull qwen3:8b
     ```
   - 可以根据需要下载其他模型：
     ```powershell
     ollama pull llama3:8b
     ollama pull mistral:7b
     ```

### 2.3 项目代码与依赖安装

1. **克隆项目代码**
   ```powershell
   git clone <项目仓库地址>
   cd ConsensusWeaverAgent
   ```

2. **创建虚拟环境并安装所有依赖**
   ```powershell
   uv venv && uv sync --all-extras
   ```
   
   这条命令会：
   - 创建一个名为`.venv`的虚拟环境
   - 自动安装项目的所有依赖（包括开发依赖）
   - 确保依赖版本兼容
   
3. **激活虚拟环境**
   ```powershell
   .venv\Scripts\activate
   ```

4. **下载NLTK资源**
   ```powershell
   python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet')"
   ```

## 3. 项目配置

### 3.1 配置文件创建

项目会在首次运行时自动创建默认配置文件 `config.yaml`。如果需要手动创建，可以使用以下命令：

```powershell
# 创建默认配置文件
python -c "from src.infrastructure.config.config_manager import ConfigManager; ConfigManager()"
```

### 3.2 配置文件结构

项目使用YAML格式的配置文件 `config.yaml`，默认配置如下：

```yaml
# 本地LLM配置
local_llm:
  provider: "ollama"          # LLM提供商
  model: "qwen3:8b"          # 使用的模型名称
  base_url: "http://localhost:11434"  # Ollama服务地址
  timeout: 30                 # LLM调用超时时间

# 外部AI工具配置
external_tools:
  - name: "iflow"            # 工具名称
    command: "iflow"         # 命令名称
    args: "ask --streaming=false"  # 命令参数
    needs_internet: true     # 是否需要互联网
    priority: 1              # 优先级（数字越小优先级越高）
    enabled: true            # 是否启用
  - name: "codebuddy"
    command: "codebuddy"
    args: "ask --format plain"
    needs_internet: true
    priority: 2
    enabled: true

# 网络配置
network:
  check_before_run: true     # 启动前检查网络
  timeout: 60                # 外部工具调用超时时间（秒）

# 应用配置
app:
  max_clarification_rounds: 3  # 最大澄清轮数
  max_parallel_tools: 5        # 最大并发工具数
  log_level: "info"            # 日志级别
  log_file: "consensusweaver.log"  # 日志文件路径
  history_enabled: true        # 是否启用历史记录
  history_limit: 100          # 历史记录限制数量
```

### 3.2 配置说明

- **local_llm**：配置本地LLM服务参数
  - `model`：可根据需要更改为其他Ollama支持的模型
  - `timeout`：可根据网络和模型性能调整

- **external_tools**：配置外部AI工具
  - 可以添加或删除工具
  - `enabled`：设置为false可禁用特定工具
  - `priority`：数字越小，优先级越高

- **network**：配置网络相关参数
  - `check_before_run`：设置为false可跳过网络检查
  - `timeout`：可根据网络状况调整

- **app**：配置应用行为
  - `max_clarification_rounds`：最多澄清轮数
  - `max_parallel_tools`：最大并发工具调用数量
  - `log_level`：可选值：debug, info, warning, error, critical

## 4. 项目启动

### 4.1 启动Ollama服务

Ollama服务默认在安装后自动启动。如果需要手动启动：

1. 打开命令行
2. 运行以下命令：
   ```powershell
   ollama serve
   ```

### 4.2 运行项目

1. **激活虚拟环境**（如果尚未激活）
   ```powershell
   .\venv\Scripts\activate
   ```

2. **运行应用**
   ```powershell
   python -m src.main
   ```

3. **带参数运行**
   ```powershell
   # 指定配置文件
   python -m src.main --config my_config.yaml
   
   # 启用详细日志
   python -m src.main --verbose
   ```

## 5. 开发流程

### 5.1 代码结构

```
src/
├── ui/                     # 用户界面层
├── service/                # 应用服务层
│   ├── interaction/        # 智能交互引擎
│   └── strategy/           # 执行策略管理器
├── core/                   # 核心功能层
│   ├── executor/           # 并发查询执行器
│   ├── analyzer/           # 共识分析引擎
│   └── reporter/           # 报告生成器
├── infrastructure/         # 基础设施层
│   ├── llm/                # LLM集成服务
│   ├── tools/              # 外部工具集成
│   ├── data/               # 数据持久化
│   ├── config/             # 配置管理
│   └── logging/            # 日志系统
├── models/                 # 数据模型
└── utils/                  # 工具函数
```

### 5.2 代码规范

- 使用ruff进行代码格式化和lint检查
  ```powershell
  uv run ruff check .
  uv run ruff format .
  ```
  
  我们使用uv run来运行ruff，确保使用的是虚拟环境中的ruff版本，保证环境一致性。

- 所有函数/方法必须包含完整类型注解
- 复杂结构使用`TypedDict`或`@dataclass`
- 公共模块/类/函数必须包含Google风格docstring

### 5.3 测试流程

- 运行单元测试
  ```powershell
  uv run pytest tests/unit/
  ```

- 运行集成测试
  ```powershell
  uv run pytest tests/integration/
  ```

- 运行所有测试
  ```powershell
  uv run pytest
  ```
  
  我们使用uv run来运行pytest，确保使用的是虚拟环境中的pytest版本，保证环境一致性。

## 6. 常见问题与解决方案

### 6.1 Ollama相关问题

#### 问题1：无法连接到Ollama服务

**错误信息**：`连接本地LLM服务失败: ConnectionError`

**解决方案**：
1. 确认Ollama服务已启动
2. 检查Ollama服务地址是否正确（默认：http://localhost:11434）
3. 检查防火墙设置，确保端口11434已开放

#### 问题2：模型下载失败

**错误信息**：`Error: could not pull model`

**解决方案**：
1. 检查网络连接
2. 尝试使用代理：
   ```powershell
   set HTTP_PROXY=http://your-proxy:port
   set HTTPS_PROXY=http://your-proxy:port
   ollama pull qwen3:8b
   ```
3. 手动下载模型文件并放置到Ollama模型目录

### 6.2 Python依赖问题

#### 问题1：模块导入错误

**错误信息**：`ModuleNotFoundError: No module named 'xxx'`

**解决方案**：
1. 确认虚拟环境已激活
2. 安装缺失的依赖：
   ```powershell
   uv install xxx
   ```

#### 问题2：版本冲突

**错误信息**：`ImportError: cannot import name 'xxx' from 'yyy'`

**解决方案**：
1. 升级或降级相关依赖：
   ```powershell
   uv install yyy==version
   ```
2. 查看项目的依赖关系：
   ```powershell
   uv show yyy
   ```

### 6.3 应用运行问题

#### 问题1：外部工具调用失败

**错误信息**：`工具 xxx 执行失败: returncode: 1`

**解决方案**：
1. 确认外部工具已正确安装
2. 检查工具是否需要API密钥或其他配置
3. 检查网络连接（如果工具需要联网）

#### 问题2：内存不足

**错误信息**：`MemoryError` 或 `OOM killed`

**解决方案**：
1. 关闭其他占用内存的程序
2. 使用较小的LLM模型
3. 增加系统内存

## 7. 开发工具推荐

### 7.1 IDE推荐
- **VS Code**：轻量级，插件丰富
  - 推荐插件：Python, Pylance, Ruff, YAML

- **PyCharm**：功能强大，专为Python开发设计
  - 推荐版本：PyCharm Community或Professional

### 7.2 调试工具
- **Python Debugger**：VS Code内置调试器
- **pytest**：测试框架，支持调试

### 7.3 版本控制
- **Git**：代码版本管理
  - 推荐使用GitHub Desktop或SourceTree等图形界面工具

## 8. 联系与支持

如果在环境搭建过程中遇到问题，可以通过以下方式寻求支持：

- 团队内部技术群
- 项目GitHub Issues
- 联系项目维护人员

---

**更新时间**：2026-01-16
**文档版本**：v1.0
**适用项目**：ConsensusWeaverAgent
